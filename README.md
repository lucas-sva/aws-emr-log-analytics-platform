# AWS EMR Log Analytics Platform

![Terraform](https://img.shields.io/badge/terraform-%235835CC.svg?style=for-the-badge&logo=terraform&logoColor=white)
![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black)
![GitHub Actions](https://img.shields.io/badge/github%20actions-%232671E5.svg?style=for-the-badge&logo=githubactions&logoColor=white)

## üìã Overview

Plataforma de Engenharia de Dados projetada para ingerir e analisar logs de seguran√ßa (Web Server Logs) em escala. A arquitetura utiliza **Terraform** para provisionamento de infraestrutura imut√°vel e **Amazon EMR com Apache Spark** para processamento distribu√≠do em lote (Batch), com foco agressivo em otimiza√ß√£o de custos (FinOps).

### üéØ Business Case
Em cen√°rios de Ciberseguran√ßa, o volume de logs gerados pode atingir Terabytes rapidamente. Analisar esses dados manualmente √© invi√°vel. Este projeto automatiza o processamento massivo de logs armazenados no Data Lake (S3), permitindo a detec√ß√£o de padr√µes maliciosos e gerando relat√≥rios consolidados de forma escal√°vel e audit√°vel.

## üèóÔ∏è Arquitetura da Solu√ß√£o

![Diagrama de Arquitetura EMR Log Analytics](docs/img/arquitetura-emr.png)

A plataforma implementa um **Data Lakehouse** modular na AWS, priorizando seguran√ßa e isolamento de recursos. O fluxo de dados segue o modelo de camadas (Medallion Architecture simplificada):

### 1. Camada de Armazenamento (Data Lake)
Utilizamos o **Amazon S3** segregado em buckets l√≥gicos:
* **Raw Zone (Bronze):** Recebe os logs brutos (ex: arquivos `.txt` gerados pelo servidor de aplica√ß√£o). A ingest√£o √© preparada para arquivos imut√°veis.
* **Processed Zone (Silver):** Armazena os dados limpos, tipados e convertidos para **Parquet**, particionados por status code para otimiza√ß√£o de leitura.
* **Administrative Zone:** Armazena artefatos de infraestrutura, como scripts de Bootstrap (`init.sh`) e Jobs Spark (`.py`), al√©m de logs de auditoria do cluster.

### 2. Camada de Processamento (Compute)
O processamento √© realizado via **Amazon EMR (Elastic MapReduce)** vers√£o 7.1.0:
* **Engine:** Apache Spark para processamento distribu√≠do em mem√≥ria.
* **Estrat√©gia FinOps:** Uso de **Instance Fleets** combinando inst√¢ncias On-Demand (Master) para estabilidade e Spot (Tasks) para redu√ß√£o de custos.
* **Bootstrap Actions:** Scripts Shell que rodam na inicializa√ß√£o das m√°quinas para instalar depend√™ncias Python e configurar o ambiente.

### 3. Seguran√ßa e Networking (Zero Trust)
A infraestrutura de rede foi desenhada para n√£o expor dados:
* **VPC Customizada:** O Cluster EMR reside inteiramente em **Subnets Privadas**, sem IPs p√∫blicos.
* **Sa√≠da Controlada:** O acesso √† internet (para baixar libs Python) √© feito via **NAT Gateway** na subnet p√∫blica.
* **Acesso Interno:** A comunica√ß√£o com o S3 utiliza **VPC Endpoints** (Gateway), garantindo que o tr√°fego de dados massivos n√£o saia da rede interna da AWS (reduzindo lat√™ncia e custo).
* **Criptografia:** Dados criptografados em repouso (SSE-S3) e tr√¢nsito (TLS).

## üöÄ Quick Start

### Pr√©-requisitos
* Docker e Docker Compose instalados.
* Credenciais AWS configuradas em `~/.aws/credentials`.

### Como Rodar (Ambiente Isolado)

N√£o √© necess√°rio instalar Terraform ou AWS CLI na sua m√°quina. Utilizamos uma **Toolbox** containerizada para garantir reprodutibilidade.

1. **Inicie a Toolbox:**
   ```bash
   docker compose run --rm toolbox
   ```

2. **Dentro do container, fa√ßa o deploy:**
    ```bash
    cd infra/live/dev
    terraform init
    terraform apply
    ```

## üìö Documenta√ß√£o

Este reposit√≥rio serve como material de estudo. Para guias detalhados, acesse:

* **[Wiki do Projeto](../../wiki):** Cont√©m o guia detalhado de configura√ß√£o de ambiente, manuais de opera√ß√£o e detalhamento da infraestrutura.
* **[Architecture Decision Records (ADRs)](docs/adr/):** Registros hist√≥ricos do porqu√™ de cada tecnologia e padr√£o de seguran√ßa foram escolhidos (ex: Networking, Storage, compute-engine).